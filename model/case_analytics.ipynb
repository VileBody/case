{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "case_analytics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXVk5U0GBtuP"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvcv_6jwtmTl"
      },
      "source": [
        "import nltk, string\n",
        "tokenizer = nltk.WordPunctTokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APAAarY1d8IJ"
      },
      "source": [
        "import torch\n",
        "import transformers \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2oWfrVpd_Jz"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer(\n",
        "    vocab_file='ru_conversational_cased_L-12_H-768_A-12_pt/vocab.txt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxnqxqyBqUWw"
      },
      "source": [
        "from tqdm import notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gKBbHGsqsCr"
      },
      "source": [
        "config = transformers.BertConfig.from_json_file(\n",
        "    'ru_conversational_cased_L-12_H-768_A-12_pt/bert_config.json')\n",
        "model = transformers.BertModel.from_pretrained(\n",
        "    'ru_conversational_cased_L-12_H-768_A-12_pt/pytorch_model.bin', config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQQ0_Jt7KORM"
      },
      "source": [
        "marked = pd.read_excel('/content/drive/My Drive/marked.xlsx', index_col=0).dropna().reset_index(drop=True)\n",
        "marked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvIuE-X3IiRv"
      },
      "source": [
        "data = pd.read_excel('/content/drive/My Drive/marked.xlsx', index_col=0).reset_index(drop=True).loc[:500]\n",
        "data['flood'] = 0\n",
        "data['mark'] = data['mark'].fillna(2)\n",
        "data.loc[data['mark']==2, 'flood'] = 1\n",
        "data.loc[data['mark']==2, 'mark'] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC4GdNhiKmsE"
      },
      "source": [
        "tokenizer_ = nltk.WordPunctTokenizer()\n",
        "def clear_text(raw):\n",
        "  line = tokenizer_.tokenize(raw.lower())\n",
        "  filtered_line = [w for w in line if all(c not in string.punctuation+''.join([str(x) for x in range(0, 10)]) for c in w) and len(w) > 3]\n",
        "  return ' '.join(filtered_line)\n",
        "marked['cl_text'] = marked['text'].apply(clear_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYqbYVWfLBNm"
      },
      "source": [
        "tokenized = marked['cl_text'].apply(\n",
        "    lambda x: tokenizer.encode(x, add_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6DpcMOuLStl"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
        "\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX7NRKj1LWY2"
      },
      "source": [
        "batch_size = 4\n",
        "embeddings = []\n",
        "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
        "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
        "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
        "        \n",
        "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zkTGxo_MGW0"
      },
      "source": [
        "mark_embs = np.concatenate(embeddings)\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_test, target_train, target_test = train_test_split(mark_embs, marked['mark'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtBA8a0e5WES"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "net = keras.models.Sequential()\n",
        "\n",
        "\n",
        "net.add(keras.layers.BatchNormalization(input_dim=768))\n",
        "net.add(keras.layers.Dense(units=768*2,  activation='relu'))\n",
        "net.add(keras.layers.Dropout(0.5))\n",
        "net.add(keras.layers.BatchNormalization(input_dim=768))\n",
        "net.add(keras.layers.Dropout(0.5))\n",
        "net.add(keras.layers.Dense(units=2,  activation='softmax'))\n",
        "\n",
        "net.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "net.fit(features_train, target_train, epochs=34, verbose=2,\n",
        "          validation_data=(features_test, target_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKZp0blg9kZI",
        "outputId": "707749a1-bcb0-4c1b-9ce7-8eef0c88966c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preds = [0 if x>y else 1 for x, y in net(features_test).numpy()]\n",
        "f1_score(target_test, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7499999999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    }
  ]
}